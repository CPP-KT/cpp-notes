<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js ayu">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Многопоточность - C++ course notes</title>
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "ayu";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('ayu')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="course.html"><strong aria-hidden="true">1.</strong> About &amp; Links</a></li><li class="chapter-item expanded "><a href="01_asm.html"><strong aria-hidden="true">2.</strong> Введение в ассемблер</a></li><li class="chapter-item expanded "><a href="02_os_cpu.html"><strong aria-hidden="true">3.</strong> Прерывания, страничная адресация и т.д.</a></li><li class="chapter-item expanded "><a href="03_cache_pipelines.html"><strong aria-hidden="true">4.</strong> Кэши, конвейер</a></li><li class="chapter-item expanded "><a href="04_syntax_types.html"><strong aria-hidden="true">5.</strong> Пересечение синтаксиса C/C++, типы данных</a></li><li class="chapter-item expanded "><a href="05_compilation.html"><strong aria-hidden="true">6.</strong> Этапы компиляции</a></li><li class="chapter-item expanded "><a href="06_classes.html"><strong aria-hidden="true">7.</strong> Классы, абстракция данных</a></li><li class="chapter-item expanded "><a href="07_classes_memory_preprocessor.html"><strong aria-hidden="true">8.</strong> Ещё про классы, выделение памяти, препроцессор</a></li><li class="chapter-item expanded "><a href="08_inheritance.html"><strong aria-hidden="true">9.</strong> Наследование, виртуальные функции</a></li><li class="chapter-item expanded "><a href="09_exceptions.html"><strong aria-hidden="true">10.</strong> Исключения, гарантии безопасности исключений, RAII</a></li><li class="chapter-item expanded "><a href="10_memory_allocation.html"><strong aria-hidden="true">11.</strong> Механизмы ОС для аллокации памяти, аллокаторы памяти, small-object и copy-on-write оптимизации, статические и динамические библиотеки</a></li><li class="chapter-item expanded "><a href="11_templates.html"><strong aria-hidden="true">12.</strong> Шаблоны (templates)</a></li><li class="chapter-item expanded "><a href="12_stl_sfinae.html"><strong aria-hidden="true">13.</strong> Обзор STL, tag-dispatching, SFINAE, пространства имён</a></li><li class="chapter-item expanded "><a href="13_namespaces_using_adl.html"><strong aria-hidden="true">14.</strong> Пространства имён, using-декларации, using-директивы, ADL</a></li><li class="chapter-item expanded "><a href="14_move_rvalue.html"><strong aria-hidden="true">15.</strong> Move-семантика, rvalue-ссылки</a></li><li class="chapter-item expanded "><a href="15_intrusive_containers.html"><strong aria-hidden="true">16.</strong> Интрузивные контейнеры</a></li><li class="chapter-item expanded "><a href="16_smart_pointers.html"><strong aria-hidden="true">17.</strong> Smart pointers: unique_ptr, shared_ptr, weak_ptr</a></li><li class="chapter-item expanded "><a href="17_perfect_forwarding.html"><strong aria-hidden="true">18.</strong> Perfect forwarding, variadic templates</a></li><li class="chapter-item expanded "><a href="18_decltype_auto_nullptr.html"><strong aria-hidden="true">19.</strong> Decltype, declval, auto, nullptr</a></li><li class="chapter-item expanded "><a href="19_lambdas_type_erasure.html"><strong aria-hidden="true">20.</strong> Анонимные функции, type erasure, std::function</a></li><li class="chapter-item expanded "><a href="20_signals_reetrancy_errors.html"><strong aria-hidden="true">21.</strong> Сигналы, reetrancy, обработки ошибок</a></li><li class="chapter-item expanded "><a href="21_optional_variant_tuple_stringview.html"><strong aria-hidden="true">22.</strong> Optional, variant, tuple, string_view</a></li><li class="chapter-item expanded "><a href="22_constexpr.html"><strong aria-hidden="true">23.</strong> Статическая и динамическая инициализация, constexpr</a></li><li class="chapter-item expanded "><a href="23_multithreading.html" class="active"><strong aria-hidden="true">24.</strong> Многопоточность</a></li><li class="chapter-item expanded "><a href="24_qt.html"><strong aria-hidden="true">25.</strong> Qt</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu (default)</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">C++ course notes</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        <a href="https://github.com/lejabque/cpp-notes" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#Многопоточность" id="Многопоточность">Многопоточность</a></h1>
<ul>
<li><a href="https://www.youtube.com/watch?v=q9A2nvqW0QQ">Запись лекции №1</a></li>
<li><a href="https://www.youtube.com/watch?v=ebb2IYxlSPU">Запись лекции №2</a></li>
<li><a href="https://www.youtube.com/watch?v=DvBpHBsdWew">Запись лекции №3</a></li>
<li><a href="https://www.youtube.com/watch?v=A8eCGOqgvH4">C++ and Beyond 2012: Herb Sutter - atomic Weapons 1 of 2</a></li>
<li><a href="https://www.youtube.com/watch?v=KeLBd2EJLOU">C++ and Beyond 2012: Herb Sutter - atomic Weapons 2 of 2</a></li>
<li><a href="https://www.youtube.com/watch?v=RtQqEre0Ag8">Запись лекции №4</a></li>
<li><a href="https://www.youtube.com/watch?v=HcIaqm9b5hU">Запись лекции №5</a></li>
<li><a href="https://www.youtube.com/watch?v=VogqOscJYvk">CppCon 2019: Olivier Giroux “The One-Decade Task: Putting std::atomic in CUDA.”</a></li>
<li><a href="https://www.youtube.com/watch?v=SiGqozCBXDE">Запись лекции №6</a></li>
</ul>
<h2><a class="header" href="#Зачем-нужна" id="Зачем-нужна">Зачем нужна?</a></h2>
<p><em>Поток исполнения - независимая последовательность выполнения инструкций внутри одного процесса с общей памятью, но собственными регистрами и стеком</em>.</p>
<p>Банальное применение - чтобы использовать несколько имеющихся ядер, необходимо в программе завести несколько потоков.</p>
<p>Стоит отметить, что нагрузить ядра можно не только несколькими потоками, но и несколькими процессами. Кроме того, API для работы с несколькими потоками появился ещё до того, как процессоры с несколькими ядрами стали популярными - получается, что потребность в потоках возникла не только для нагрузки ядер. Одна из потребностей заключается в использовании потоков для функций, которые должны работать параллельно основной программе (запускаем какую-нибудь функцию из библиотеки, но не хотим, чтобы она была блокирующей - например, если параллельно нужно читать ввод от пользователя).</p>
<p>API для работы с потоками в C++ появился в 11-м стандарте и был расширен в 20-м. До этого стандарт не предоставлял ничего для работы с многопоточными программами, поэтому люди делали всё средствами ОС.</p>
<h2><a class="header" href="#stdthread" id="stdthread">std::thread</a></h2>
<p>Просто пример:</p>
<pre><code class="language-c++">int main() {
    std::thread th([]{
        std::cout &lt;&lt; &quot;Hello, world!\n&quot;;
    });
    th.join();
}
</code></pre>
<p>Конструктор <code>std::thread</code> принимает функциональный объект, который нужно исполнить в другом потоке. </p>
<p>Деструктор потока аварийно завершает программу вызовом <code>std::terminate</code>, если на момент вызова деструктора поток все ещё работает и не была сделана ни одна из следующих операций: <code>join</code> - дождаться, пока поток выйдет, <code>detach</code> - &quot;отделить поток&quot;, он продолжит исполняться, а объект <code>std::thread</code> перестанет быть привязан к этому потоку.</p>
<p>Может возникнуть вопрос, почему не выбрали одну из этих операций, чтобы вызывать её дефолтно в деструкторе. Если это был бы <code>detach</code>, то не понятно, что происходит в таком случае:</p>
<pre><code class="language-c++">int main() {
    std::thread th([]{
        std::cout &lt;&lt; &quot;Hello, world!\n&quot;;
    });
    th.detach();
}
</code></pre>
<p>После выхода из <code>main</code> всё равно все потоки будут убиты при завершении программы, кроме того, при выходе из <code>main</code> вызываются деструкторы глобальных переменных (например, <code>std::cout</code>), к которым может обращаться поток, поэтому делать <code>detach</code> не очень хорошо. В принципе, <code>detach</code> нужен вообще достаточно редко, потому что в основном поток привязан к каким-то глобальным данным (как в примере выше, к глобальной переменной <code>std::cout</code>). </p>
<p>Делать <code>join</code> по дефолту тоже не сработает - некоторые потоки могут остаться бесконечно ждать, если потоку не сообщили, что он должен выходить (например, если поток повиснет в ожидании ввода каких-нибудь данных).</p>
<p>В C++20 появился механизм, позволяющий сообщить потоку, что ему нужно выходить. В связи с этим появился <code>std::jthread</code>, деструктор которого по умолчанию сообщает потоку, что нужно выйти, а потом делает <code>join</code>.</p>
<p>Способа принудительно завершить поток в стандартной библиотеке нет. Если бы такой способ был, то он бы завершал поток в неопределённой точке, что было бы странно для многих программ - например, если бы тред делал какие-то операции со структурой данных, в таком случае она бы осталась в невалидном состоянии.</p>
<p>Такие механизмы есть у ОС - в Windows есть <code>TerminateThread</code>, в описании которого сказано следующее: <em>You should call TerminateThread only if you know exactly what the target thread is doing, and you control all of the code that the target thread could possibly be running at the time of the termination.</em> В принципе, её можно было бы использовать, если мы точно уверены, что поток крутится в каком-нибудь бесконечном цикле и не делает в нём никаких выделений памяти и не трогает глобальные данные. Из-за того, что такая фича редко нужна, она не была внесена в стандартную библиотеку.</p>
<h2><a class="header" href="#stdmutex" id="stdmutex">std::mutex</a></h2>
<pre><code class="language-c++">std::array&lt;int, 1000&gt; accounts;

void transfer(size_t to, size_t from, int amount) {
    if (accounts[from] &lt; amount) {
        throw std::runtime_error(&quot;insufficient funds&quot;);
    }
    accounts[from] -= amount;
    accounts[to] += amount;
}
</code></pre>
<p>Если функция <code>transfer</code> вызывается из нескольких потоков, то это считается UB. Может возникнуть следующая проблема: если вызывается <code>transfer(1, 2, 100)</code> из двух разных потоков, а <code>accounts[2] == 101</code>, то может возникнуть так, что они оба сначала проверят, что на счету достаточно денег, а потом вычтут по 100. Кроме того, нет никакой гарантии, что операция <code>-=</code> транслируется не в одну инструкцию, а в несколько, что тоже может вызвать проблему. В общем случае, такую проблему называют <em>race condition</em> (состояние гонки). </p>
<p>Нам может помочь примитив синхронизации под названием <em>mutex</em> (от слов <em>mutual exclusion</em> - взаимное исключение). В стандартной библиотеке это класс <code>std::mutex</code> с двумя операциями: <code>lock</code> и <code>unlock</code>. У него может быть два состояния - разблокирован (по умолчанию при создании) и разблокирован. Вызов <code>lock</code> ждёт, пока <code>mutex</code> будет разблокирован, а потом блокирует его. Метод <code>unlock</code>, очевидно, разблокирует <code>mutex</code>. </p>
<pre><code class="language-c++">std::mutex m;
std::array&lt;int, 1000&gt; accounts;

void transfer(size_t to, size_t from, int amount) {
    m.lock();
    if (accounts[from] &lt; amount) {
        m.unlock();
        throw std::runtime_error(&quot;insufficient funds&quot;);
    }
    accounts[from] -= amount;
    accounts[to] += amount;
    m.unlock();
}
</code></pre>
<p>В стандартной библиотеке есть <code>std::lock_guard</code> - RAII-обёртка над мьютексом, которая в конструкторе блокирует его, а в деструкторе разблокирует. Кроме того, обычно мьютекс привязан к каким-то данным, а не функциям, работающим с ними - например, в примере выше, идейно можно думать, что это часть <code>accounts</code>, поэтому иногда мьютекс с данными можно объединить в один объект.</p>
<p>Проблема такого примера в том, что мы блокируем все аккаунты одновременно, лишаясь параллельности. С одной стороны, это плохо, с другой, функция <code>transfer</code> не обязательна должна уметь параллельно работать с несколькими аккаунтами - например, если программа в несколько потоков делает кучу другой работы, но иногда вызывает <code>transfer</code>. Здесь можно сослаться на известный <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Закон Амдала</a>, который говорит о том, что рост производительности с увеличением числа потоков, ограничен долей операций, которые можно идеально распараллелить.</p>
<p>Допустим, что нам хочется, чтобы независимые по данным вызовы функции <code>transfer</code> могли работать параллельно - можно создать больше мьютексов! Такой приём называется <em>мелкогранулярными блокировками</em>. </p>
<pre><code class="language-c++">struct account {
    std::mutex m;
    int32_t balance;
};

std::array&lt;account, 1000&gt; accounts;

void transfer(size_t to, size_t from, int amount) {
    std::lock_guard&lt;std::mutex&gt; lg_from(accounts[from].m);
    std::lock_guard&lt;std::mutex&gt; lg_to(accounts[to].m);
    if (accounts[from].balance &lt; amount) {
        throw std::runtime_error(&quot;insufficient funds&quot;);
    }
    accounts[from].balance -= amount;
    accounts[to].balance += amount;
}
</code></pre>
<p>И тут мы сталкиваемся с ситуацией, которая называется <em>deadlock</em>: при вызовах <code>transfer(a, b, 42)</code>, <code>transfer(b, a, 42)</code> может произойти так, что первый поток залочит мьютекс <code>a</code>, второй залочит <code>b</code> и в итоге первый поток будет бесконечно ждать <code>b</code>, который заблокирован вторым потоком, который бесконечно ждёт <code>a</code>, в итоге программа зависнет. Формально, <em>deadlock</em> - это ситуация, при которой ни один поток находится в ожидании ресурсов, занятых друг другом, и не может продолжить своё исполнение.</p>
<p>Это фиксится введением порядка на мьютексах - назначим им номера и введём на них отношения порядка, в котором будем их блокировать (например, в примере выше номерами могут быть номера аккаунтов, а блокировать можно всегда меньший). <em>Кстати, повторная блокировка мьютекса внутри одного потока это UB, поэтому в примере надо проверить<code>from != to</code>.</em></p>
<p>Почему блокировать в каком-то порядке всегда это верно? Можно представить ориентированный граф, в котором вершины это мьютексы, а ребро <code>uv</code> означает, что в программе есть место, в котором, удерживая мьютекс <code>u</code>, поток попытается заблокировать мьютекс <code>v</code>. Утверждается, что если в этом графе нет циклов, то дедлок возникнуть не может. Если же на мьютексах введён порядок, то циклы возникнуть не могут, так как все рёбра будут проведены от меньшего к большему.</p>
<p>Ещё одна проблема кода выше - мьютекс на каждый аккаунт заводить дорого, так как <code>sizeof</code> мьютекса это 40 байт. Можно, к примеру, завести по мьютексу на какую-то часть аккаунтов (например, по одному на каждые 100 аккаунтов).</p>
<p>Проблема возникала из-за того, что мы блокировали один мьютекс и ждали разблокировки следующего, не отпуская заблокированный. Если бы мы, например, блокировали один, затем пробовали заблокировать второй, если же не получилось, отпускали первый и повторяли всё заново, то это позволило бы решить проблему.  У <code>std::mutex</code> есть метод <code>try_lock</code>, который возвращает <code>false</code> для заблокированного мьютекса, иначе блокирует его и возвращает <code>true</code>. </p>
<p>Кроме того, в стандартной библиотеке есть функция <code>std::lock</code>, которая блокирует несколько объектов, избегая дедлоков неспецифицированной последовательностью вызовов функций <code>lock</code>, <code>unlock</code>, <code>try_lock</code>. В таком случае нельзя использовать <code>lock_guard</code>, потому что он в конструкторе пытается залочить мьютекс. Можно воспользоваться <code>unique_lock</code>, который имеет более тонкую настройку и даёт возможность создать незаблокированный лок:</p>
<pre><code class="language-c++">void transfer(size_t to, size_t from, int32_t amount) {
    if (from == to) {
        return;
    }
    std::unique_lock&lt;std::mutex&gt; lg_from(accounts[from].m, std::defer_lock);
    std::unique_lock&lt;std::mutex&gt; lg_to(accounts[to].m, std::defer_lock);
    std::lock(lg_from, lg_to);
    // ...
}
</code></pre>
<h2><a class="header" href="#stdcondition_variable" id="stdcondition_variable">std::condition_variable</a></h2>
<p>Нельзя просто вставить в каждую функцию очереди мьютекс:</p>
<pre><code class="language-c++">template &lt;typename T&gt;
struct concurrent_queue {
    void push(T value) {
        std::lock_guard&lt;std::mutex&gt; lg(m);
        q.push_back(std::move(value));
    }
    
    bool empty() const {
        std::lock_guard&lt;std::mutex&gt; lg(m);
        return q.empty();
    }
    
    T pop() {
        std::lock_guard&lt;std::mutex&gt; lg(m);
        T result = q.front();
        q.pop_front();
        return result;
    }
private:
    mutable std::mutex m;
    std::deque&lt;T&gt; q;
};
</code></pre>
<p>Это не будет работать, когда функция <code>pop</code> вызывается одним потоком у непустой очереди, но пока он ждёт мьютекс, другой поток её опустошает. Одно из решений - возвращать <code>std::optional&lt;T&gt;</code>  из <code>pop</code>.</p>
<p>Иногда может понадобиться &quot;ждущий pop&quot;. Например, можно крутить в цикле какой-нибудь <code>try_pop</code>, но это не очень выгодно - он не будет совершать полезной работы. Появляется желание уметь &quot;усыпить поток&quot; и потом &quot;пробудить его&quot; из другого потока - для этого существует специальный класс <code>std::condition_variable</code>. С помощью него можно переписать очередь следующим образом:</p>
<pre><code class="language-c++">template &lt;typename T&gt;
struct concurrent_queue {
    void push(T value) {
        std::unique_lock&lt;std::mutex&gt; lg(m);
        q.push_back(std::move(value));
        lg.unlock();
        cv.notify_one();
    }

    bool empty() const {
        std::lock_guard&lt;std::mutex&gt; lg(m);
        return q.empty();
    }

    T pop() {
        std::unique_lock&lt;std::mutex&gt; lg(m);
        cv.wait(lg, [&amp;] {
            return !q.empty();
        });
        T result = q.front();
        q.pop_front();
        return result;
    }
private:
    mutable std::mutex m;
    std::deque&lt;T&gt; q;
    std::condition_variable cv;
};
</code></pre>
<p>У него существует несколько операций:</p>
<ul>
<li>wait - поток начинает спать</li>
<li>notify_one - пробуждает один поток</li>
<li>notify_all - пробуждает все потоки</li>
</ul>
<p><code>wait</code> принимает в качестве аргумента <code>unique_lock</code>. Это нужно, чтобы между <code>unlock</code> и вызовом <code>wait</code> другой поток ничего не испортил. </p>
<p>У <code>wait</code> есть две перегрузки - одна принимает только лок, а вторая ещё и предикат. <code>wait</code>, принимающий предикат, эквивалентен следующему:</p>
<pre><code class="language-c++">while (!pred()) {
    wait(lock);
}
</code></pre>
<p>Так как между пробуждением потока и захватом блокировки, условие может нарушиться другим потоком, проверку нужно крутить в цикле. Кроме того, потоки могут случайно пробуждаться (<em>spurious wakeup</em>) без нотифая.</p>
<p>Существует специальная перегрузка у <code>wait</code> для таких ситуаций:</p>
<pre><code class="language-c++">cv.wait(lg, [&amp;]{
    return !q.empty();
})
</code></pre>
<p>Кажется, что можно оптимизировать функцию <code>push</code> следующим образом  - если очередь не пуста, то не пробуждать потоки.</p>
<pre><code class="language-c++">void push(T value) {
    std::lock_guard&lt;std::mutex&gt; lg(m);
    bool was_empty = q.empty()
    q.push_back(std::move(value));
    if (was_empty) {
        cv.notify_one();
    }
}
</code></pre>
<p>Проблема в том, что если ждут несколько <code>pop</code>, то может произойти следующее: в очередь произойдёт вставка, она сделает notify только одного <code>pop</code>, затем произойдёт ещё несколько вставок, которые не пробудят другие <code>pop</code>, потому что очередь ещё не пуста.</p>
<p>Может появиться желание ограничить размер очереди, например, если в неё пушат сильно быстрее, чем попают. В таком случае можно сделать ждущий <code>push</code>, заведя для этого вторую <code>condition_variable</code>. </p>
<h2><a class="header" href="#Как-это-устроено-внутри" id="Как-это-устроено-внутри">Как это устроено внутри?</a></h2>
<p>Для реализации этих примитивов нужно иметь возможность &quot;усыпить поток&quot;, что возможно только с использованием средств ОС. В игрушечных реализациях используют <code>sleep</code> или <code>std::this_thread::yield</code>. Проблема <code>yield</code> в том, что операционная система (а конкретно scheduler) может решить продолжить выполнять этот поток, даже если есть другие кандидаты - как минимум, переключаться на другой поток дороже из-за сброса TLB-кэша и т.д. В ОС есть специальные операции, которые в каком-то смысле говорят, что данный поток будет ждать чего-то. В Linux это называется <code>futex</code>, который говорит, что поток будет ждать &quot;по какой-то переменной/адресу в памяти&quot; и пробуждает другой поток. </p>
<p>Бывают случаи, когда засыпать потоку может быть невыгодно и можно просто немного подождать, пока мьютекс не разлочится. Для этого применяется примитив синхронизации под названием <code>spinlock</code>, который просто крутится в цикле, проверяя, не залочен ли. Большинство реализацией мьютексов совмещают эти подходы: крутятся в цикле какое-то время, а потом засыпают, если мьютекс не разблокировался. В x86 есть специальная инструкция <em>Spin Loop Hint</em>, которую можно вставить внутрь цикла спинлока, чтобы процессор как-нибудь оптимизировал это.</p>
<h2><a class="header" href="#stdatomic" id="stdatomic">std::atomic</a></h2>
<p>В начале лекции мы говорили о том, что многопоточный не read-only доступ к обычным данным это UB. Почему так было специфицировано? </p>
<p>Во-первых, на это влияет количество разных архитектур процессоров - во многих из них отличаются инструкции, они предоставляют разные гарантии. Во-вторых, не любую переменную можно модифицировать атомарно. Атомарность - это неделимость операции с точки зрения других потоков (&quot;они не видят её промежуточного результата&quot;). Особенно это вызывает проблемы, если переменная находится на стыке кэш-линий, из-за чего возникает необходимость атомарно работать с двумя кэш-линиями сразу, в x86 такое возможно, но со спецэффектами уровня &quot;другие ядра не могут читать из памяти в этот момент&quot; (гуглится по запросу <a href="https://lwn.net/Articles/790464/">split lock</a>). </p>
<p>В C++ есть класс <code>std::atomic</code> со специализациями для всех встроенных (и не только) типов, предоставляющий атомарный доступ к переменным. Несмотря на то, что многие операции для него транслируются в те же инструкции, что и операции с обычными переменными (например, в x86 <code>load</code> и <code>store</code> для <code>std::atomic&lt;int&gt;</code> это будет просто <code>mov</code>), нельзя считать, что можно пользоваться обычными типами вместо атомиков. Во-первых, в разных архитектурах атомики могут транслироваться в разные инструкции (например, в ARM для этого есть специальные инструкции). Во-вторых, обычные переменные могут по-разному оптимизироваться компилятором, потому что они не дают никаких гарантий на многопоточный доступ.</p>
<p>Через <code>std::atomic</code> первый пример можно переписать так:</p>
<pre><code class="language-c++">std::array&lt;std::atomic&lt;int32_t&gt;, 1000&gt; accounts;

void transfer(size_t to, size_t from, int amount) {
    if (from == to) {
        return;
    }
    int32_t old = accounts[from].load();
    do {
        if (old &lt; amount) {
            throw std::runtime_error(&quot;insufficient funds&quot;)
        }
    } while (!accounts[from].compare_exchange_weak(old, old - amount));
    accounts[to].fetch_add(amount);
}

int32_t get_balance(size_t account) {
    return accounts[account].load();
}
</code></pre>
<p>Операция <code>compare_exchange</code> принимает два аргумента <code>expected</code> и <code>desired</code> и записывает в атомик значение <code>desired</code>, если там записано значение <code>expected</code>, иначе в <code>expected</code> записывается значение из атомика.</p>
<p>Есть <code>compare_exchange_weak</code> и <code>compare_exchange_strong</code>:<code>weak</code>-форме разрешено &quot;спонтанно фейлиться&quot; (вести себя так, будто <code>*this != excepted</code>, даже если они равны), <code>strong</code>-форма гарантирует ожидаемое поведение (внутри там что-то вроде цикла). В случаях, как выше, выгоднее использовать <code>weak</code>-форму, потому что у нас уже есть внешний цикл. На x86 разницы между ними нет, там обе формы выражаются одной ассемблерной инструкцией.</p>
<h3><a class="header" href="#memory_order" id="memory_order">memory_order</a></h3>
<p>Почти у всех операций с атомиками есть дополнительный параметр <code>memory_order</code>, у которого всегда есть дефолтное значение. На эту тему рекомендуется посмотреть <a href="https://www.youtube.com/watch?v=A8eCGOqgvH4">C++ and Beyond 2012: Herb Sutter - atomic Weapons 1 of 2</a>, далее следует краткий пересказ основных поинтов доклада.</p>
<p>В упрощённой модели программа исполняется следующим образом: есть какие-то ядра, они соединены в память, из которой они читают и в которую они пишут. Реальный мир устроен не так: есть память, есть кэши разных уровней, какие-то из уровней общие для нескольких ядер и т.д. В такой системе дорого поддерживать иллюзию наивного представления &quot;процессор - память&quot;, но как может быть по-другому? Самый простой пример - из-за бранч-предиктора процессор может читать спекулятивно из памяти или просто префетчить при последовательном чтении, аналогично запись может быть отложенной.</p>
<p>То, в каком порядке ядро читает из памяти и пишет в неё становится непредсказуемым из-за оптимизаций, хотя в x86 есть некоторые гарантии на это, о них можно почитать в <a href="https://software.intel.com/content/www/us/en/develop/download/intel-64-and-ia-32-architectures-sdm-combined-volumes-1-2a-2b-2c-2d-3a-3b-3c-3d-and-4.html">Intel Software Developer Manual</a>: чтения не переупорядочиваются с другими чтениями, записи не переупорядочиваются с чтениями, идущими до них, записи не переупорядочиваются с другими записями кроме некоторых исключений, чтения <em>могут быть</em> переупорядочены с идущими до них записями в другие места памяти. На эту тему есть <a href="https://www.realworldtech.com/forum/?threadid=173441&amp;curpostid=192262">забавный пример</a> о том, что даже в однопоточной программе в зависимости от порядка инструкций меняется производительность, потому что процессор обязан соблюдать ордеринг. Для борьбы с реордерингом применяются так называемые <a href="https://vedmysh.livejournal.com/5558.html">барьеры памяти</a>.</p>
<p><strong>Пример:</strong></p>
<pre><code class="language-c++">std::atomic&lt;int&gt; x, y;

void thread_1() {
    x.store(1);
}

void thread_2() {
    y.store(1);
}

void thread_3() {
    int x3 = x.load();
    int y3 = y.load();
    if (x3 == 1 &amp;&amp; y3 == 0) {
        std::cout &lt;&lt; &quot;x written before y\n&quot;;
    }
}

void thread_4() {
    int y4 = y.load();
    int x4 = x.load();
    if (y4 == 1 &amp;&amp; x4 == 0) {
        std::cout &lt;&lt; &quot;y written before x\n&quot;;
    }
}
</code></pre>
<p>Представим, что все 4 потоки запускаются одновременно. Если <code>x3 = y3</code>, то поток 3 отработал раньше (или позже)  обоих потоков 1 и 2, случай неинтересный, если <code>x3 = 0, y3 = 1</code>, то запись в <code>y</code> могла случиться после чтения <code>x</code>, поэтому ничего сказать нельзя. Интересен один случай - когда <code>x3 = 1, y3 = 0</code>, тогда точно можно сказать, что запись в <code>x</code> произошла раньше записи в <code>y</code>. Аналогично если <code>y4 = 1, x4 = 0</code>, то запись в <code>y</code> произошла раньше записи в <code>x</code>.</p>
<p>Кажется логичным, что одновременно нельзя получить два сообщения - и это правда для атомиков в C++, они гарантируют такое поведение, потому что для locked инструкций реордеринг не наблюдается (например, для записи в атомике используется инструкция <code>xchg</code>, которая по умолчанию считается locked). Но на многих архитектурах обычные операции чтения и записи не обеспечивают такой гарантии. Это означает, что потоки 3 и 4 видят записи от других потоков в разном порядке. Такое, в принципе, может происходит из-за того, на каких ядрах они исполняются, так же на это влияют и кэши. В x86 такого эффекта нет, но в мануале есть интересная фраза &quot;Any two stores are seen in a consistent order by processors other than those perfoming the stores&quot;, самый известный пример на эту тему - <a href="https://preshing.com/20120515/memory-reordering-caught-in-the-act/">Memory Reordering Caught in the Act</a>.</p>
<p>В некоторых случаях можно ослабить лишние гарантии для атомиков, чтобы получиться большую эффективность. Для этого и нужен <code>memory_order</code>.</p>
<pre><code class="language-c++">std::string value;
std::atomic&lt;bool&gt; value_present;

void produce() {
    value = &quot;hello&quot;;
    value_present.store(true, std::memory_order_release);
    // ... 
}

void try_consume() {
    if (value_present.load(std::memory_order_acquire)) {
        std::string  tmp = value;
    }
}
</code></pre>
<p>Все операции, сделанные до <code>memory_order_release</code> не могут быть сделаны после него, аналогично все операции, сделанные после <code>memory_order_acquire</code> не могут быть сделаны до него, и есть дополнительное правило, что если один поток записал в переменную с ордерингом <code>release</code>, а другой прочитал с ордерингом <code>acquire</code>, то все записи, сделанные в первом потоке, будут сделаны до всех чтений во втором потоке. Пример выше без них накладывает больше ненужных гарантий, которые как раз ослабляются параметром <code>memory_order</code>.</p>
<p>Если посмотреть, во что это транслируется, то будет видно, что с дефолтным <code>memory_order</code> запись делается инструкцией <code>xchg</code>, а в случае с <code>memory_order_release</code>, там будет <code>mov</code>.</p>
<p>Ещё есть <code>memory_order_relaxed</code>, который не накладывает дополнительных ограничений на упорядочивание этой операции. По сути, <code>relaxed</code> означает, что &quot;значение когда-нибудь запишется&quot;, а нужный ордеринг обеспечивается за счёт других вещей, например, это может быть <code>join</code>, который гарантирует, что все записи потока, который джойнится, будут видны из того, который вызывает <code>join</code>. </p>
<pre><code class="language-c++">void thread1() {
    for (;;) {
        // ...
        number_of_events.fetch_add(1, std::memory_order_relaxed);
    }
}

int main() {
    std::thread th(&amp;thread 1);
    // ...
    th.join();
    number_of_events.load(std::memory_order_relaxed);
}
</code></pre>
<p>Также <code>memory_order_relaxed</code> можно использовать при записи в память до создания других потоков, потому что  их создание так же гарантирует, что они увидят все записи, сделанные до этого.</p>
<p>Если посмотреть на <a href="https://www.cl.cam.ac.uk/%7Epes20/cpp/cpp0xmappings.html">маппинг</a> между операциями атомика и инструкциями процессора, то для x86 имеет смысл использовать разные <code>memory_order</code> только для записи, потому что там любой <code>load</code> мапится в <code>mov</code>.</p>
<h2><a class="header" href="#volatile" id="volatile">volatile</a></h2>
<p>Модификатор <code>volatile</code> у переменных в C++ никак не связан с многопоточностью. Если вы вдруг забыли это, то есть <a href="http://cxx.isvolatileusefulwiththreads.com/">полезный сайт</a>, к которому всегда можно обратиться.</p>
<p>Почему у людей возникает сомнение в этом? Во-первых, <code>volatile</code> в других языках имеет другой смысл: например, в Java это аналог атомиков. Во-вторых, строго говоря, набор ограничений на volatile переменные похож на те, которые накладываются на атомики, но не одинаков. В-третьих, до C++11 и в Си <code>volatile</code> использовался при работе с потоками - например, в MSVC есть ключик для совместимости со старыми программами, заменяющий <code>volatile</code> переменные на атомики.</p>
<p>Для чего на самом деле используется <code>volatile</code>? </p>
<ul>
<li>Device memory: подавить оптимизации компилятора при работе с памятью какого-либо устройства (например, чтобы компилятор не заменял несколько записей подряд на последнюю из них)</li>
<li>setjmp/longjmp: что-то из Си, нам неактуально, можете погуглить</li>
<li>UNIX-signal: если внешний обработчик сигнала работает с переменными, то они должны быть <code>volatile</code></li>
</ul>
<pre><code class="language-c++">volatile int a;
void foo() {
    a = 1;
    a = 2; // компилятор обязан сохранить порядок записи
}

std::atomic&lt;int&gt; b;
void bar() {
    b.store(1);
    b.store(2); // компилятор имеет право оставить только запись 2, сделав вид, что другой поток не успел прочитать между записью 1 и 2
    b.load(); // может не читать
}

void progress_bar() {
    for (size_t i = 0; i != 10000; ++i) {
        // ...
        b += 1;
    }
    // может быть соптимизировано в b += 10000; снаружи цикла
}
</code></pre>
<p>Но при этом обычно компилятор не оптимизирует такие штуки,  потому что это может испортить смысл программы  (как в примере с <code>progress_bar</code>), а так же на самом деле редко встречаются юзкейсы, когда можно так соптимизировать. Подробнее про это можно прочитать <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4455.html">No Sane Compiler Would Optimize Atomics</a>.</p>
<h2><a class="header" href="#Кэш-и-многопоточные-программы" id="Кэш-и-многопоточные-программы">Кэш и многопоточные программы</a></h2>
<p>Есть вот такой пример:</p>
<pre><code class="language-c++">namespace po = boost::program_options;

void thread_proc(std::atomic&lt;int&gt;&amp; v, std::atomic&lt;bool&gt;&amp; finish) {
    while (!finish.load()) {
        v += 1;
    }
}

int main(int argc, char* argv[]) {
    try {
        po::options_description desc(&quot;Allowed options&quot;);
        desc.add_options()(&quot;threads,j&quot;, po::value&lt;size_t&gt;(), &quot;set number of threads&quot;);
        po::variables_map vm;
        po::store(po::parse_command_line(argc, argv, desc), vm);
        po::notify(vm);
        size_t number_of_threads = 1;
        if (vm.count(&quot;threads&quot;) != 0) {
            number_of_threads = vm[&quot;threads&quot;].as&lt;size_t&gt;();
        }
        for (;;) {
            std::cout &lt;&lt; number_of_threads &lt;&lt; &quot; threads&quot;;
            std::atomic&lt;int&gt; val(0);
            std::atomic&lt;bool&gt; finished(value);
            std::vector&lt;std::threads&gt; threads;
            for (size_t i = 0; i != number_of_threads; ++i) {
                threads.emplace_back(&amp;thread_proc, std::ref(val), std::ref(finished));
            }
            std::this_thread::sleep_for(std::chrono::seconds(2));
            finished.store(true);
            for (auto i = threads.rbegin(); i != threads.rend(); ++i) {
                auto&amp; th = *j;
                th.join();
            }
            std::cout &lt;&lt; &quot;, &quot; &lt;&lt; val.load() &lt;&lt; &quot; iterations&quot; &lt;&lt; std::endl;
        }
    } catch(std::exception const&amp; e) {
        std::cer &lt;&lt; e.what() &lt;&lt; std::endl;
        return EXIT_FAILURE;
    }
}
</code></pre>
<p>Эта программа принимает аргументом число <code>N</code> и создаёт <code>N</code> потоков, которые внутри себя инкрементят переменную <code>val</code> в цикле, пока их не остановит значение переменной <code>finished</code>, которое записывается через 2 секунды. В итоге выводим сколько раз за 2 секунды <code>N</code> потоков инкрементят переменную <code>val</code>. Интересно следующее - как при увеличении числа потоков изменится значение переменной.</p>
<p>При запуске на одном потоке результат получился в 4 раза больше, чем на двух потоках, при этом на двух потоках результат получился <em>шумным</em> (скачет от 2 до 4 раз). При увеличении числа потоков дальше результат остаётся примерно одинаковым. </p>
<p>Дело в том, что работать из разных потоков с одной переменной одновременно всё равно нельзя - инкременты у процессора будут выполняться последовательно, поэтому получить результат лучше, чем на одном потоке, не получится. Почему результат для двух потоков был шумным и в несколько раз хуже? Ответ кроется в кэшах - запись в переменную от одного ядра инвалидирует её в других кэшах.</p>
<p>С помощью команды <code>taskset</code> можно ограничить ядра, на которых запускается программа. Если запускать с двумя потоками на ядрах 0, 1 (которые на самом деле одно физическое ядро, просто hyperthreading, а значит кэш у них общий), то результат примерно такой же, как если запускать программу в один поток. Если же запустить на ядрах 0, 2 (разные физические ядра), то результат в 4 раза хуже и при этом он не шумит, потому что кэш у них разный. Шумный результат означал, что иногда планировщик закидывал потоки на одно физическое ядро, а иногда на разные.</p>
<p>Один из способов решения такой проблемы - делать по переменной на каждый поток, а в конце складывать результаты. Давайте заведём <code>N</code> этих переменных:</p>
<pre><code class="language-c++">std::vector&lt;std::atomic&lt;int&gt;&gt; vals(number_of_threads);
</code></pre>
<p>И каждому потоку выдадим по своей переменной.</p>
<p>Кажется, что должно стать лучше, ведь теперь все потоки пишут в разные переменные, но результат получился тот же: для одного потока результат тот же,  для двух потоков получили в 2-3 раза меньше итераций. Аналогично с исполнениями на одном ядре и на разных. Проблема опять в кэше - соседние переменные из вектора попадают в одну кэш-линию, поэтому, несмотря на то, что переменные разные, один поток инвалидирует кэш-линию, которая нужна второму потоку. Кроме того, даже один и тот же поток может перекидываться ОС с одного ядра на другое, что тоже сказывается на производительности (хоть и не так заметно). Кстати, для двух потоков стало чуть быстрее, чем в прошлом случае <em>TODO: почему - не понятно, если знаете, допишите</em>.</p>
<p>Можно аккуратно подобрать оффсет так, чтобы переменные для разных потоков попадали в разные кэш-линии. Размер кэш-линии на x86 64 байта, размер атомик инта 4 байта, поэтому кажется, что надо делать сдвиг на 16. Тогда при запуске на разных ядрах двух потоков результат получается в 2 раза больше, чем при запуске на одном ядре. </p>
<p>Если покрутить значения, то заметно, что при сдвиге меньше 8 на двух потоках результат как на одном, при сдвиге больше 8 результат на двух потоках стабильно в 2 раза больше. Откуда берётся число 8, если мы посчитали, что сдвиг должен быть равен 16? Вектор выделяет память, выравнивая по 32 байта, поэтому он мог выделить память так, что первые 8 элементов попали в одну кэш-линию, а следующие 8 уже в следующую, поэтому и было достаточно сдвига 8. </p>
<h2><a class="header" href="#Применение-многопоточности" id="Применение-многопоточности">Применение многопоточности</a></h2>
<p>Самый канонический пример многопоточности - аллокаторы памяти. Раньше, когда процессоры были одноядерные, проблема нескольких потоков была проблемой корректности, а не перфоманса, поэтому в аллокаторах памяти просто все операции оборачивали в мьютексы. В многоядерных процессорах это стало приводить к проблемам - если два потока аллоцируют и освобождают память в процессе работы, при этом не работая с общими данными, узким местом будет аллокатор памяти.</p>
<p>Один из первых известных аллокаторов с понятными описанием это <a href="http://hoard.org/">Hoard</a>. Хоть он и устарел и на практике уже давно не применяется, концепции, описанные там, переняли разработчики других аллокаторов.  Они попытались сделать так, чтобы аллокатор хорошо масштабировался на много потоков, при этом пытаясь избежать <em>false sharing</em> памяти, которую возвращает аллокатор - например, если аллокатор выделил два куска памяти для разных потоков, они не должны попадать в одну кэш-линию. </p>
<p>Концептуально они добились этого тем, что сделали <code>N</code> копий однопоточного аллокатора, назначая каждому потоку аллокатор по хешу потока, в итоге потоки равномерно распределяются по аллокаторам, кроме того случая, когда один поток выделил память, а другой освобождает её (в таком случае освобождать должен аллокатор первого потока). Заведение нескольких копий позволило решить проблему <em>false sharing</em> - нужно просто гарантировать, что каждая кэш-линия принадлежит хипу ровно одного из аллокаторов. Ещё один хак - если поток обращается к аллокатору, а тот залочен, он может переходить к следующему и так, пока не найдёт свободный, который он запомнит и будет дальше обращаться только к нему. Подробнее про всё это можно почитать в <a href="https://people.cs.umass.edu/%7Eemery/pubs/berger-asplos2000.pdf">пейпере по Hoard</a>.</p>
<h2><a class="header" href="#Пример-про-дедлок" id="Пример-про-дедлок">Пример про дедлок</a></h2>
<pre><code class="language-c++">struct integer_generator {
    integer_generator(std::function&lt;void (uint64_t)&gt; on_next_number, uint64_t val)
        : on_next_number(std::move(on_next_number))
        , current_val(val)
        , quit(false)
        , inner_thread([this] { thread_proc(); }) {}

    integer_generator(integer_generator const&amp;) = delete;
    integer_generator&amp; operator=(integer_generator const&amp;) = delete;

    ~integer_generator(){
        {
            std::lock_guard&lt;std::mutex&gt; lg(m1);
            quit = true;
        }
        inner_thread.join();
    }

    void reset(uint64_t val) {
        std::lock_guard&lt;std::mutex&gt; lg(m1);
        current_val = val;
    }
private:
    void thread_proc() {
        for (;;) {
            std::lock_guard&lt;std::mutex&gt; lg(m1);
            if (quit)
                break;
            ++current_val;
            on_next_number(current_val);
        }
    }
    
    std::mutex m1;
    std::function&lt;void (uint64_t)&gt; const on_next_number;
    uint64_t current_val;
    bool quit;
    std::thread inner_thread;
};

struct integer_accumulator
{
    integer_accumulator(uint64_t sum, uint64_t val)
        : current_sum(sum)
        , gen([this] (uint64_t next) {
            std::lock_guard&lt;std::mutex&gt; lg(m2);
            current_sum += next;
            std::cout &lt;&lt; &quot;sum = &quot; &lt;&lt; current_sum &lt;&lt; &quot;, &quot; &lt;&lt; next &lt;&lt; '\n';
        }, val) {}

    void reset(uint64_t sum, uint64_t val) {
        std::lock_guard&lt;std::mutex&gt; lg(m2);
        current_sum = sum;
        gen.reset(val);
    }

private:
    std::mutex m2;
    uint64_t current_sum;
    integer_generator gen;
};
int main() {
    integer_accumulator acc(0, 0);
    for (;;) {
        std::this_thread::sleep_for(std::chrono::milliseconds(1));
        acc.reset(0, 0);
    }
}
</code></pre>
<p>Класс <code>integer_generator</code> хранит внутри себя поток <code>inner_thread</code>, который создаётся в конструкторе и крутится, пока не <code>quit</code>, вызывая функцию <code>on_next_number</code> с увеличивающимся каждый раз значением. Функция <code>reset</code> сбрасывает текущее значение. В деструкторе <code>quit</code> присваивается <code>true</code> и джойнится поток.</p>
<p>Класс <code>integer_accumulator</code> создаёт генератор, передавая функцию для суммирования чисел. </p>
<p>В примере дедлок - <code>acc.reset</code> берёт мьютекс <code>m2</code> и, удерживая его, заходит в <code>gen.reset</code> и пытается взять мьютекс <code>m1</code>, а в <code>thread_proc</code> происходит наоборот: берётся <code>m1</code>, вызывается <code>on_next_number</code>, который пытается взять <code>m2</code>.</p>
<p>Одно из решений - объединить эти мьютексы в один, другое - заметить, что при вызове <code>on_next_number</code> не требуется удерживать мьютекс <code>m1</code>, но для этого нужно копировать <code>current_val</code>, а это может быть дорого или вообще запрещено в случае более сложного объекта.</p>
<p>Пример может показаться надуманным, но такое возникает достаточно часто, если писать многопоточный код, разбивая на классы. Одна из формулировок, которую используют - &quot;не нужно делать коллбэки (в примере это функция <code>on_next_number</code>), удерживая мьютекс&quot;, другая - &quot;то, какие мьютексы удерживает класс - часть интерфейса&quot;. Интересно, что в примере оба класса по отдельности корректны, но вместе вызывают дедлок. Получается, что рассуждая о корректности программы, нужно знать, что генератор, вызывая коллбэк, держит тот же внутренний мьютекс, что и лочит <code>reset</code>. Это можно считать проблемой того, как код разбит на классы.</p>
<h2><a class="header" href="#cancellation" id="cancellation">cancellation</a></h2>
<p>Почти наверняка, когда запускаем какой-то поток или даём какому-то потоку сделать какую-то операцию, от него хочется получить какой-то ответ или результат. Есть проблема - может произойти так, что в момент, когда операция завершится, её результат уже не будет никому нужен, тогда возникает несколько вопросов - не получится ли так, что когда операция завершилась, поток обращается к каким-то несуществующим объектам или из программы вышли совсем. Это пример, когда полезна следующая техника <em>cancellation</em> - сообщить потоку, что он больше не нужен и может выходить, например, это можно сделать через <code>std::atomic&lt;bool&gt;</code>.</p>
<p>В C++20 такое стандартизовали, появился <code>std::jthread</code> с похожим функционалом. У него есть <code>stop_token</code>:</p>
<pre><code class="language-c++">int main() {
    std::jthread jt{ [](std::stop_token st) {
        while (!st.stop_requested()) {
            // ...
        }
    }};
    sleep(5);
    jt.request_stop();
    jt.join();
}
</code></pre>
<p><code>request_stop</code> устанавливает <code>stop_token</code>. Деструктор <code>jthread</code> так же вызывает <code>request_stop</code>, если он не был вызван до удаления объекта, и делает <code>jt.join()</code>. Кстати, тут видно, что удобно думать о потоках как об обычных ресурсах.</p>
<p>Здесь возникает сразу несколько проблем. Во-первых, <code>stop_token</code> внутри нужно достаточно часто проверять, чтобы обеспечить реакцию на отмену потока. Во-вторых, даже если проверять часто, во время блокирующих операций (в том числе банального взятия мьютекса) не получится прервать поток. Блокирующие операции специфичны для операционной системы, поэтому нужно пользоваться механизмами, которые предоставляет ОС. </p>
<h2><a class="header" href="#Асинхронные-операции" id="Асинхронные-операции">Асинхронные операции</a></h2>
<p>Вместо блокирующих операций можно использовать асинхронные операции, которые более-менее независимо появились в UI и в серверных программах. </p>
<p>Как работает сервер: у него есть <code>n</code> клиентов, из каждого из которых он хочет читать, поэтому просто так делать блокирующие операции не получается. Традиционно делали следующее: каждому соединению заводили поток, что не очень экономно. </p>
<p>Альтернативный подход - спросить у ОС, у какого из сокетов (или файловых дескрипторов), можно &quot;взять данные&quot;, такой механизм называется <code>poll</code>, он пробегается по всему массиву файловых дескрипторов и проверяет, готовы ли они. Недостаток <code>poll</code> в том, что он не возвращает, какие именно дескрипторы готовы. Продвинутая его версия - <code>epoll</code>, в который можно не сразу передать <code>n</code> дескрипторов, а добавлять их или убирать по одному. В отличие от <code>poll</code>, он возвращает список только тех дескрипторов, для которых произошли события. Подробнее и понятнее можно почитать в <a href="https://habr.com/ru/company/infopulse/blog/415259/">статье на хабре</a>.</p>
<p>Операции такого рода называются асинхронными. Преимущества таких операций в том, что не нужно создавать много потоков, можно самостоятельно приоритизировать сокеты.</p>
<p>Кроме сетевых программ, асинхронные операции нужны в UI-программах. Различные ивенты (нажатие кнопки, клик мышки и т.д.) складывают в одну очередь, не заводя отдельные потоки. Часто внутри там тоже  <code>epoll</code>.</p>
<p><em>Тут был пример UI-программы на QT,  смотрите <a href="https://youtu.be/SiGqozCBXDE?t=1627">запись</a></em>.</p>
<h2><a class="header" href="#Про-блокирующие-операции-и-cancellation" id="Про-блокирующие-операции-и-cancellation">Про блокирующие операции и cancellation</a></h2>
<p>Пусть есть поток, который повис на одной из блокирующих операций. Как убить такой поток? Поскольку все эти операции зависят от ОС, то и механизмы cancellation'а специфичны для ОС. </p>
<p>Просто пример - сокеты. У них есть функция <code>shutdown</code>, которая отменяет вызов <code>recv</code> на сокете. После её вызова, с сокетом работать нельзя. <strong>Важно</strong>: не нужно пытаться вызывать <code>close</code>, это не отменит блокирующую операцию.</p>
<p>Пусть есть поток, который сидит в вызове <code>sleep</code>. Как его прервать? Прямого способа нет, поэтому нужно начать издалека и поговорить про <a href="https://man7.org/linux/man-pages/man7/signal.7.html">UNIX-сигналы</a> (не надо путать с сигналами, о которых говорили на прошлых лекциях). Сигналы похожи на прерывания, но внутри одного процесса. Например, обращение по нулевому указателю, программа прерывается с сигналом <code>SIGSEGV</code>. На самом деле, программа может зарегистрировать функцию, которая называется обработчик сигнала и будет вызвана на него. Обработчик сигнала может быть вызван на любой инструкции, поэтому  он не может полагаться на какое-либо состояние программы, вследствие чего внутри обработчика сигнала можно пользоваться ограниченным набором системных вызовов.</p>
<pre><code class="language-c++">void sigsegv_handler(int) {
    int a = 5;
}
int* p;
int main() {
    struct sigaction new_action;
    new_action.sa_handler = &amp;sigsegv_handler;
    sigemptyset(&amp;new_action.sa_mask);
    new_action.sa_flags = 0;
    sigaction(SIGSEGV, &amp;new_action, nullptr);
    *p = 42; // SIGSEGV
}
</code></pre>
<p>Если потоку приходит сигнал, то системные вызовы либо дорабатывают до начала обработки сигнала, либо возвращают код ошибки. Это сделано для того, чтобы избежать ситуации, когда обработчик сигнала вызывают системный вызов, на инструкции которого он уже был вызван.</p>
<p>На линуксе есть ещё одно API:</p>
<pre><code class="language-c++">void thread_proc() {
    for (;;) {
        pthread_testcancel();
    }
}
int main() {
    pthread_cancel(handle);
}
</code></pre>
<p>Как это работает? <code>pthread_testcancel()</code> пробрасывает исключение, если поток отменён.  Его можно использовать самостоятельно, но в куче блокирующих операций из стандартной библиотеки эта проверка уже стоит (например, в read). Применяется это как-то так:</p>
<pre><code class="language-c++">int main() {
    std::thread th([]{
        for (;;) {
            std::string s;
            std::cin &gt;&gt; s; // блокирующая, внутри есть pthread_testcancel
            // вылетает abi::__forced_unwind
            if (!std::cin) {
                break;
            }
            std::cout &lt;&lt; s &lt;&lt; '\n';
        }
    });
    std::this_thread::sleep_for(std::chrono::seconds(1));
    pthread_cancel(th.native_handle());
    th.join();
}
</code></pre>
<p>Хоть это API и кажется удобным, но его хейтят по некоторым причинам:</p>
<ul>
<li>
<p>Код, через который пролетает исключение, должен быть exception-safe: сложно использовать в коде на Си.</p>
</li>
<li>
<p>Если где-то используется <code>noexcept</code>, то исключение, которое вылетает при отмене потока, нарушает эти гарантии.</p>
</li>
<li>
<p>В некоторых кастомных реализациях стандартной библиотеки нет пробрасывания исключения при отмене потока, в них поток просто убивают, из-за чего деструкторы не вызываются. </p>
</li>
<li>
<p><code>abi::__force_unwind</code> нельзя ловить и не пробрасывать, поэтому, если в программе есть <code>catch(...)</code>, который не пробрасывает исключение, тогда <code>pthread_cancel</code> тоже использовать нельзя.</p>
</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="22_constexpr.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        

                        
                            <a rel="next" href="24_qt.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a rel="prev" href="22_constexpr.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                

                
                    <a rel="next" href="24_qt.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        

    </body>
</html>
