# Многопоточность

- [Запись лекции №1](https://www.youtube.com/watch?v=q9A2nvqW0QQ)

## Зачем нужна? 

*Поток исполнения - независимая последовательность выполнения инструкций внутри одного процесса с общей памятью, но собственными регистрами и стеком*.

Банальное применение - чтобы использовать несколько имеющихся ядер, необходимо в программе завести несколько потоков.

Стоит отметить, что нагрузить ядра можно не только несколькими потоками, но и несколькими процессами. Кроме того, API для работы с несколькими потоками появился ещё до того, как процессы с несколькими ядрами стали популярными - получается, что потребность в потоках возникла не только для нагрузки ядер. Одно из применений - использовать потоки для функций, которые должны работать параллельно основной программе (запускаем какую-нибудь функцию из библиотеки, но не хотим, чтобы она была блокирующей - например, если параллельно нужно читать ввод от пользователя).

API для работы с потоками в C++ появился в 11-м стандарте и был расширен в 20-м. До этого стандарт не предоставлял ничего для работы с многопоточными программами, поэтому люди делали всё средствами ОС.

## std::thread

Просто пример:

```c++
int main() {
	std::thread th([]{
        std::cout << "Hello, world!\n";
    });
    th.join();
}
```

Конструктор `std::thread` принимает функциональный объект, который нужно исполнить в другом потоке. 

Деструктор потока аварийно завершает программу вызовом `std::terminate`, если на момент вызова деструктора поток все ещё работает и не была сделана ни одна из следующих операций: `join` - дождаться, пока поток выйдет, `detach` - "отделить поток", он продолжит исполняться, а объект `std::thread` перестанет быть привязан к этому потоку.

Может возникнуть вопрос, почему не выбрали одну из этих операций, чтобы вызывать её дефолтно в деструкторе. Если это был бы `detach`, то не понятно, что происходит в таком случае:

```c++
int main() {
	std::thread th([]{
        std::cout << "Hello, world!\n";
    });
    th.detach();
}
```

После выхода из `main` всё равно все потоки будут убиты при завершении программы, кроме того, при выходе из `main` вызываются деструкторы глобальных переменных (например, `std::cout`), к которым может обращаться поток, поэтому делать `detach` не очень хорошо. В принципе, `detach` нужен вообще достаточно редко, потому что в основном поток привязан к каким-то глобальным данным (как в примере выше, к глобальной переменной `std::cout`). 

Делать `join` по дефолту тоже не сработает - некоторые потоки могут остаться бесконечно ждать, если потоку не сообщили, что он должен выходить (например, если поток повиснет в ожидании ввода каких-нибудь данных).

В C++20 появился механизм, позволяющий сообщить потоку, что ему нужно выходить. В связи с этим появился `std::jthread`, деструктор которого по умолчанию сообщает потоку, что нужно выйти, а потом делает `join`.

Способа принудительно завершить поток в стандартной библиотеке нет. Почему? Если бы такой способ был, то он бы завершал поток в неопределённой точке, что было бы странно для многих программ - например, если бы тред делал какие-то операции со структурой данных, в таком случае она бы осталась в невалидном состоянии. Такие механизмы есть у ОС - в Windows есть `TerminateThread`, в описании которого сказано следующее: *You should call TerminateThread only if you know exactly what the target thread is doing, and you control all of the code that the target thread could possibly be running at the time of the termination.* В принципе, её можно было бы использовать, если мы точно уверены, что поток крутится в каком-нибудь бесконечном цикле и не делает в нём никаких выделений памяти и не трогает глобальные данные. Из-за того, что такая фича редко нужна, она не была внесена в стандартную библиотеку.

## std::mutex

```c++
std::array<int, 1000> accounts;

void transfer(size_t to, size_t from, int amount) {
	if (accounts[from] < amount) {
        throw std::runtime_error("insufficient funds");
    }
    accounts[from] -= amount;
    accounts[to] += amount;
}
```

Если функция `transfer` вызывается из нескольких потоков, то это считается UB. Может возникнуть следующая проблема: если вызывается `transfer(1, 2, 100)` из двух разных потоков, а `accounts[2] == 101`, то может возникнуть так, что они оба сначала проверят, что на счету достаточно денег, а потом вычтут по 100. Кроме того, нет никакой гарантии, что операция `-=` транслируется не в одну инструкцию, а в несколько что тоже может вызвать проблему. В общем случае, такую проблему называют *race condition* (состояние гонки). 

Нам может помочь примитив синхронизации под названием *mutex* (от слов *mutual exclusion* - взаимное исключение). В стандартной библиотеке это класс `std::mutex` с двумя операциями: `lock` и `unlock`. У него может быть два состояния - разблокирован (по умолчанию при создании) и разблокирован. Вызов `lock` ждёт, пока `mutex` будет разблокирован, а потом блокирует его. Метод `unlock`, очевидно, разблокирует `mutex`. 

```c++
std::mutex m;
std::array<int, 1000> accounts;

void transfer(size_t to, size_t from, int amount) {
    m.lock();
	if (accounts[from] < amount) {
        m.unlock();
        throw std::runtime_error("insufficient funds");
    }
    accounts[from] -= amount;
    accounts[to] += amount;
    m.unlock();
}
```

В стандартной библиотеке есть `std::lock_guard` - RAII-обёртка над мьютексом, которая в конструкторе блокирует мьютекс, а в деструкторе разблокирует. Кроме того, обычно мьютекс привязан к каким-то данным, а не функциям, работающим с ними - например, в примере выше, идейно можно думать, что это часть `accounts`, поэтому иногда мьютекс с данными можно объединить в один объект.

Проблема такого примера в том, что мы блокируем все аккаунты одновременно, лишаясь параллельности. С одной стороны, это плохо, с другой, функция `transfer` не обязательна должна уметь параллельно работать с несколькими аккаунтами - например, если программа в несколько потоков делает кучу другой работы, но иногда вызывает `transfer`. Здесь можно сослаться на известный [Закон Амдала](https://en.wikipedia.org/wiki/Amdahl%27s_law), который говорит о том, что рост производительности с увеличиением числа потоков, ограничен долей операций, которые можно идеально распараллелить.

Допустим, что нам хочется, чтобы независимые по данным вызовы функции `transfer` могли работать параллельно - можно создать больше мьютексов! Такой приём называется *мелкогранулярными блокировками*. 

```c++
struct account {
    std::mutex m;
    int32_t balance;
};

std::array<account, 1000> accounts;

void transfer(size_t to, size_t from, int amount) {
    std::lock_guard<std::mutex> lg_from(accounts[from].m);
    std::lock_guard<std::mutex> lg_to(accounts[to].m);
	if (accounts[from].balance < amount) {
        throw std::runtime_error("insufficient funds");
    }
    accounts[from].balance -= amount;
    accounts[to].balance += amount;
}
```

И тут мы сталкиваемся с ситуацией, которая называется *deadlock*: при вызовах `transfer(a, b, 42)`, `transfer(b, a, 42)` может произойти так, что первый поток залочит мьютекс `a`, второй залочит `b` и в итоге первый поток будет бесконечно ждать `b`, который заблокирован вторым потоком, который бесконечно ждёт `a`, в итоге программа зависнет. Формально, *deadlock* - это ситуация, при которой ни один поток находится в ожидании ресурсов, занятых друг другом, и не может продолжить своё исполнение.

Это фиксится введением порядка на мьютекса - назначим им номера и введём на них отношения порядка, в котором будем их блокировать (например, в примере выше номерами могут быть номера аккаунтов, а блокировать можно всегда меньший). *Кстати, повторная блокировка мьютекса внутри одного потока это UB, поэтому в примере надо проверить`from != to`.*

Почему блокировать в каком-то порядке всегда это верно? Можно представить ориентированный граф, в котором вершины это мьютексы, а ребро `uv` означает, что в программе есть место, в котором, удерживая мьютекс `u`, поток попытается заблокировать мьютекс `v`. Утверждается, что если в этом графе нет циклов, то дедлок возникнуть не может. Если же на мьютексах введён порядок, то цикла возникнуть не могут, так как все рёбра будут проведены от меньшего к большему.

Ещё одна примера кода выше - мьютекст на каждый аккаунт заводить дорого, так как `sizeof` мьютекса это 40 байт. Можно, к примеру, завести по мьютексу на какую-то часть аккаунтов (например, по мьютексу на каждые 100 аккаунтов).

Проблема возникала из-за того, что мы блокировали один мьютекс и ждали разблокировки следующего, не отпуская заблокированный. Если бы мы, например, блокировали один, затем пробовали заблокировать второй, если же не получилось, отпускали первый и повторяли всё заново, то это позволило бы решить проблему.  У `std::mutex` есть метод `try_lock`, который возвращает `false` для заблокированного мьютекста, иначе блокирует его и возвращает `true`. 

Кроме того, в стандартной библиотеке есть функция `std::lock`, которая блокирует несколько объектов, избегая дедлоков неспецифицированной последовательностью вызовов функций `lock`, `unlock`, `try_lock`. В таком случае нельзя использовать `lock_guard`, потому что он в конструкторе пытается залочить мьютекс. Можно воспользоваться `unique_lock`, который имеет более тонкую настройку и даёт возможность создать незаблокированный лок:

```c++
void transfer(size_t to, size_t from, int32_t amount) {
    if (from == to) {
        return;
    }
    std::unique_lock<std::mutex> lg_from(accounts[from].m, std::defer_lock);
    std::unique_lock<std::mutex> lg_to(accounts[to].m, std::defer_lock);
    std::lock(lg_from, lg_to);
    // ...
}
```

## std::conditional_variable

Нельзя просто вставить в каждую функцию очереди мьютекс:
```c++
template <typename T>
struct concurrent_queue {
    void push(T value) {
        std::lock_guard<std::mutex> lg(m);
        q.push_back(std::move(value));
    }
    
    bool empty() const {
        std::lock_guard<std::mutex> lg(m);
        return q.empty();
    }
    
    T pop() {
        std::lock_guard<std::mutex> lg(m);
        T result = q.front();
        q.pop_front();
        return result;
    }
private:
    mutable std::mutex m;
    std::deque<T> q;
}
```

Это не будет работать, когда функция `pop` вызывается одним потоком у непустой очереди, но пока он ждёт мьютекс, другой поток её опустошает. Одно из решений - возвращать `std::optional<T>`  из `pop`.

Иногда может понадобиться "ждущий pop". Например, можно крутить в цикле какой-нибудь `try_pop`, но это не очень выгодно - он не будет совершать полезной работы. Появляется желание уметь "усыпить поток" и потом "пробудить его" из другого потока - для этого существует специальный класс `std::conditional_variable`. С помощью него можно переписать очередь следующим образом:

```c++
template <typename T>
struct concurrent_queue {
    void push(T value) {
        std::lock_guard<std::mutex> lg(m);
        q.push_back(std::move(value));
		lg.unlock();
        cv.notify_one();
    }
    
    bool empty() const {
        std::lock_guard<std::mutex> lg(m);
        return q.empty();
    }
    
    T pop() {
        std::unique_lock<std::mutex> lg(m);
        while (q.empty()) {
            cv.wait(lg);
            lg.lock();
        }
        T result = q.front();
        q.pop_front();
        return result;
    }
private:
    mutable std::mutex m;
    std::deque<T> q;
    std::conditional_variable cv;
}
```

У него существует несколько операций:

- wait - поток начинает спать
- notify_one - пробуждает один поток
- notify_all - пробуждает все потоки

`wait` принимает в качестве аргумента `unique_lock`. Это нужно, чтобы между `unlock` и вызовом `wait` другой поток ничего не испортил. В примере выше `while` в тех случаях, когда между пробуждением потока и захватом блокировки, условие снова другим потоком нарушается.

Существует специальная перегрузка у `wait` для таких ситуаций:

```c++
cv.wait(lg, [&]{
    return !q.empty();
})
```

Кажется, что можно оптимизировать функцию `push` следующим образом  - если очередь не пуста, то не пробуждать потоки.

```c++
void push(T value) {
	std::lock_guard<std::mutex> lg(m);
	bool was_empty = q.empty()
	q.push_back(std::move(value));
	if (was_empty) {
		cv.notify_one();
	}
}
```

Проблема в том, что если ждут несколько `pop`, то при нескольких вставок в очередь подряд, пробудится только один `pop`, если он не успеет отработать до добавления следующего элемента.

Может появиться желание ограничить размер очереди, например, если в неё пушат сильно быстрее, чем попают. В таком случае можно сделать ждущий `push`, заведя для этого вторую `conditional_variable`. 

## Как это устроено внутри?

Для реализации этих примитивов нужно иметь возможность "усыпить поток", что возможно только с использованием средств ОС. В игрушечных реализациях используют `sleep` или `std::this_thread::yield`. Проблема `yield` в том, что операционная система (а конкретно scheduler) может решить продолжить выполнять этот поток, даже если есть другие кандидаты - как минимум, переключаться на другой поток дороже из-за сброса TLB-кэша и т.д. В ОС есть специальные операции, которые в каком-то смысле говорят, что данный поток будет ждать чего-то. В Linux это называется `futex`, который говорит, что поток будет ждать "по какой-то переменной. адресу в памяти" и пробуждает другой поток. 

Бывают случаи, когда засыпать потоку может быть невыгодно и можно просто немного подождаться, пока мьютекс не разлочится. Для этого применяется примитив синхронизации под названием `spinlock`, который просто крутится в цикле, проверяя, не залочен ли. Большинство реализацией мьютексов совмещают эти подходы: крутятся в цикле какое-то время, а потом засыпают, если мьютекс не разблокировался. В x86 есть специальная инструкция *Spin Loop Hint*, которую можно вставить внутрь цикла спинлока, чтобы процессор как-нибудьы оптимизировал это.

## std::atomic

В начале лекции мы говорили о том, что многопоточный не read-only доступ к обычным данным это UB. Почему так было специфицировано? 

Во-первых, на это влияет количество разных архитектур процессоров - во многих из них отличаются инструкции, они предоставляют разные гарантии. Во-вторых, не любую переменную можно модифицировать атомарно. Атомарность - это неделимость операции с точки зрения других потоков ("они не видят её промежуточного результата"). Особенно это вызывает проблемы, если переменная находится на стыке кэш-линий, из-за чего возникает необходимость атомарно работать с двумя кэш-линиями сразу, в x86 такое возможно, но со спецэффектами уровня "другие ядра не могут читать из памяти в этот момент" (гуглится по запросу [split lock](https://lwn.net/Articles/790464/)). 

В C++ есть класс `std::atomic` со специализациями для всех встроенных (и не только) типов, предоставляющий атомарный доступ к переменным. Несмотря на то, что многие операции для него транслируются в те же инструкции, что и операции с обычными переменными (например, в xv86 `load` и `store` для `std::atomic<int>` это будет просто `mov`), нельзя считать, что можно пользоваться обычными типами вместо атомиков. Во-первых, в разных архитектурах атомики могут транслироваться в разные инструкции (например, в ARM для этого есть специальные инструкции). Во-вторых, обычные переменные

