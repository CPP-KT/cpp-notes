# Механизмы ОС для аллокации памяти, аллокаторы памяти, small-object и copy-on-write оптимизации
- [Запись лекции №1](https://www.youtube.com/watch?v=oDPaXS9tKlw)
- [Запись лекции №2](https://www.youtube.com/watch?v=i8uYAe0E4PU)
---
*Первую часть лекции лучше смотреть запись, так как там много профилирования и я не хочу вставлять это в конспект*

## Аллокация памяти на Linux (mmap)
На Linux страницы памяти выделяются через [mmap](http://man7.org/linux/man-pages/man2/mmap.2.html), а освобождают через `munmap`. Он выделяет "лениво" и без обращений к памяти почти нет разницы, сколько выделять. Это можно заметить, если протестировать выделения с обращениями и без.

При запросе выделения памяти через `mmap` ОС не сразу обращается к процессору, а помечает у себя страницы как "заказанные". Затем когда происходит обращение к памяти, получаем ошибку `page fault`, ОС проверяет, если страница выделена, что она мапит её в физическую память, иначе это ошибка.

Зачем так сделано? Типовое использование - это не выделение одной страницы, а сразу порции памяти, которая разбивается на мелкие куски и выдается `malloc`-ом. Когда они выдаются в программе, они мапаются в физическую память. Ещё мапить сразу в физическую память не очень полезно, так как память, не принадлежащая программой, используется ОС, например, как дисковый кэш.

Зачем нам это знать? Это полезно, если мы что-то бенчмаркаем и выделяем большой массив, первый прогон какого-нибудь алгоритма может быть дольше остальных из-за 
того, что он сначала не помаплен в память.

`MAP_POPULATE` - ключ, который сразу запрашивает память так, будто к ней сделано обращение. Если делать много выделений памяти с обращениями, то можно заметить, что больше всего времени занимает функция зануления памяти. Это логично, потому что память, выделяемую программе, нужно сначала занулить, чтобы исключить доступ к старым данным других программ.

## Аллокаторы памяти
Большинство аллокаторов сейчас используют дизайн, заимствованный у аллокатора [Hoard](http://hoard.org/). В основном, аллокаторы одинаково работают именно с маленькими объектами, для работы с большими объектами разные аллокаторы используют свои фичи. Рассмотрим один из частых способов работы с маленькими объектами:

Современные аллокаторы умеют выделять их за O(1). Добиваются этого следующим образом: для каждого из частых размеров (16, 24, 32,...) генерируют отдельные аллокаторы. Как делать аллокаторы эффективно? Hashmap дорого, поэтому используют односвязный список. Но для оптимизации в самих блоках памяти, которые выделяем, кладём ноды этого списка (указатели на next).

## SO и CoW оптимизации

### Copy-on-Write
Вспомним класс `my_string` из прошлых лекций. У строки был какой-то буфер `data`, которым может заниматься достаточно много. Хотим при копировании сэкономить в случае, если после копирования не нужно изменять данные. Идея такая: когда делаем копию, копируем не данные, а просто указатель на них. При попытке модифицировать их, если буфер расшарен между несколькими string-ми, делаем копию данных.

Обычно это реализуется так: вместе с `data` храним счётчик объектов (`ref_counter`), у которых этот буфер общий. Если при попытке модификации `ref_counter > 1`, то нужно сделать копию.

```c++
struct buffer {
  size_t ref_counter;
  char chars[];
}

static buffer* allocate_buffer(size_t capacity) {
  return reinterpret_cast<buffer*>(operator new(sizeof(buffer) + (capacity + 1) * sizeof(char)));
}
```
Во всех методах класса нужно обработать счетчик ссылок (опустим этот момент) и функцию `unshare`:
```c++
void my_string::unshare() {
  buffer* new_data = allocate_buffer(size_ + 1);
  memcpy(new_data->chars, data_->chars, size);
  
  --data_->ref_counter;
  assert(data->ref_counter != 0);
}
```
Можно заметить, что `capacity` и `size` строки можно перенести тоже в буфер.

Хороший доклад про оптимизации строк от facebook с иллюстрациями по теме: [CppCon 2016: “The strange details of std::string at Facebook"](https://www.youtube.com/watch?v=kPR8h4-qZdk)

После gcc5 отказались от такого использования CoW в строчках. Первая причина - заморочки с многопоточностью, вторая - оптимизация помогает на длинных строчках, но на небольших скопировать явно может быть даже дешевле. Для маленьких строк используют:
### Small-object optimization:

Заметим, что мы хранили в буфере указатель на `size`, `capacity` и `data`, получаются накладные расходы в размере строки в ~20 символов. Что сделали в GCC: добили строчку до 32 байт, а затем `data` и `size` остаются собой, а в остальном храним либо сами данные (`data` указывает туда, где лежало `capacity`), либо `capacity` и пустой хвост. Тогда в большом количестве случаев не делаем аллокаций, а копирование стоит недорого, так как в отличие от CoW просто копируем на 15 байт больше.

Как это хранить?
```c++
struct dynamic_buffer {
  char* chars;
  size_t capacity;
}
struct small_string {
  // ...
private:
  static const size_t MAX_STATIC_DATA_SIZE = sizeof(dynamic_buffer) - 1;
  size_t size;
  union {
    dynamic_buffer dynamic_data;
    char static_buffer[sizeof(dynamic_buffer)];
  };
};
```
В `union` все поля размещаются на одном месте, поверх друг друга. Соответственно, во всех функциях нужно проверять, какой из буферов используем. 

Бонусом получаем, что со small-object оптимизацией нам нужно меньше аллокаций для маленьких строк, а ещё для них меньше кэш-мисов, так как до этого мы сначала брали указатель, а затем шли в память по нему. 


## Динамические и статические библиотеки
Тут нужно вспомнить, что мы говорили про процесс компиляции.

Программы можно объединять в статические и динамические библиотеки. Их используют, например, когда есть общий код, который мы хотим включить в несколько программ (можно скомпилировать один раз и включать в линковку другим программ, но обычно это много объектных файлов),  поэтому кучу объектных файлов объединяют в библиотеку, чтобы одним именем сослаться на них. 

```c++
// sum.cpp
int sum(int a, int b){
  return a + b;
}
// four.cpp
int sum(int a, int b);
int main(){
  std::cout << sum(2, 2);
}
// five.cpp
int sum(int a, int b);
int main(){
  std::cout << sum(2, 3);
}
```
Компилируем:
```shell
g++ -c sum.cpp -o sum.o
g++ -c four.cpp -o four.o
g++ -c five.cpp -o five.o

g++ four.o sum.o -o four
g++ five.o sum.o -o five
```
Предположим, что `sum` это не один объектный файл, а целая библиотека из кучи файлов. Хочется сослаться на неё одним именем (и распространять тоже один файл, а не кучу объектных). Для этого существуют библиотеки:

```shell
ar rcs libsum.a sum.o        # rcs - 
g++ four.o -lsum -L. -o four # -lsum - указывает на имя библиотеки
g++ five.o -lsum -L. -o five #  -L. - каталог (здесь это текущий каталог)
```

Это всё было про статическую библиотеку. В таком случае код библиотеки попадал в каждую из программ. Чтобы этого избежать, применяют динамические библиотеки:
Динамические библиотеки должны уметь подгружаться по любому адресу. Для этого нужно компилировать `sum` было с ключом `-fpic`:
```shell
g++ -fpic -c sum.cpp -o sum.o
g++ -shared sum.o -o libsum.so
```
Если сейчас мы попробуем запустить программу `four`, то получим ошибку `file not found`. Дело в том, что по умолчанию система ищет библиотеки по системным путям. Есть несколько способов обойти: вшить в бинарник путь или прописать `LD_LIBRARY_PATH`:
```shell
LD_LIBRARY_PATH=... # здесь абсолютный путь к каталогу, где лежит наша библиотека
```
Если удалить `.so` файл и попробовать запустить программы, то получим ошибку, так как они на неё ссылались.
Можно посмотреть, на какие динамические библиотеки ссылается программа:
```shell
LD_LIBRARY_PATH=... ldd ./four`
```
Библиотеки можно подключать в `cmake` коммндой `add_library`.

Полезная статья про динамические библиотеки --- [How to write shared libraries, Ulrich Drepper](https://software.intel.com/sites/default/files/m/a/1/e/dsohowto.pdf)
